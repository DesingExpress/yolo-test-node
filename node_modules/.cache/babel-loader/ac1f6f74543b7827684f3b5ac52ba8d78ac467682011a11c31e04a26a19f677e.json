{"ast":null,"code":"var _jsxFileName = \"/Users/kim-euntae/Documents/Dev/yolov8-nxv/src/components/ContentsBox.js\",\n  _s = $RefreshSig$();\nimport React, { useEffect, useRef, useState } from \"react\";\nimport { styled } from \"@mui/material\";\nimport * as tf from \"@tensorflow/tfjs\";\nimport \"@tensorflow/tfjs-backend-webgl\";\nimport { detect, detectVideo } from \"../shared/detect\";\nimport ButtonHandler from \"./BtnHandler\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst ContentContainer = /*#__PURE__*/styled(\"div\")(({\n  theme\n}) => ({\n  position: \"relative\",\n  // height: \"100%\",\n  display: \"flex\",\n  flexDirection: \"column\",\n  justifyContent: \"center\",\n  alignItems: \"center\",\n  paddingTop: \"50px\",\n  [`& > .header`]: {\n    display: \"flex\",\n    flexDirection: \"column\",\n    justifyContent: \"center\",\n    alignItems: \"center\",\n    marginBottom: \"50px\",\n    [`& > h1`]: {\n      margin: \"0 auto\"\n    }\n  },\n  [`& > div.btn-container`]: {\n    [`& > button`]: {\n      margin: \"0 8px\"\n    }\n  },\n  [`& > div.content`]: {\n    position: \"relative\",\n    paddingTop: \"50px\",\n    [`& > img`]: {\n      display: \"none\",\n      width: \"100%\",\n      maxWidth: \"720px\",\n      maxHeight: \"500px\"\n    },\n    [`& > video`]: {\n      display: \"none\",\n      width: \"100%\",\n      maxWidth: \"720px\",\n      maxHeight: \"500px\"\n    },\n    [`& > canvas`]: {\n      position: \"absolute\",\n      top: 0,\n      left: 0,\n      width: \"100%\",\n      height: \"100%\"\n    }\n  }\n}));\n_c = ContentContainer;\nfunction ContentsBox({\n  modelJSON\n}) {\n  _s();\n  const [model, setModel] = useState({\n    net: null,\n    inputShape: [1, 0, 0, 3]\n  });\n  console.log(modelJSON.weightsManifest);\n\n  // console.log(url);\n\n  const imageRef = useRef(null);\n  const cameraRef = useRef(null);\n  const videoRef = useRef(null);\n  const canvasRef = useRef(null);\n  useEffect(() => {\n    tf.ready().then(async () => {\n      const yolov8 = await tf.loadGraphModel(`${modelJSON}`, {\n        onProgress: fractions => {},\n        weightUrlConverter: n => {\n          // console.log(n);\n          return modelJSON.weightsManifest[0].paths[n];\n        }\n      });\n      const dummyInput = tf.ones(yolov8.inputs[0].shape);\n      const warmupResults = yolov8.execute(dummyInput);\n      setModel({\n        net: yolov8,\n        inputShape: yolov8.inputs[0].shape\n      });\n      canvasRef.width = yolov8.inputs[0].shape[1];\n      canvasRef.height = yolov8.inputs[0].shape[2];\n      tf.dispose([warmupResults, dummyInput]);\n    });\n  }, []);\n  return /*#__PURE__*/_jsxDEV(ContentContainer, {\n    children: [/*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"header\",\n      children: /*#__PURE__*/_jsxDEV(\"h1\", {\n        children: \"\\uD83D\\uDCF7 YOLOv8 Live Detection App\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 94,\n        columnNumber: 9\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 93,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(ButtonHandler, {\n      imageRef: imageRef,\n      cameraRef: cameraRef,\n      videoRef: videoRef\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 96,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"content\",\n      children: [/*#__PURE__*/_jsxDEV(\"img\", {\n        src: \"#\",\n        alt: \"\",\n        ref: imageRef,\n        onLoad: () => detect(imageRef.current, model, canvasRef.current)\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 102,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"video\", {\n        autoPlay: true,\n        muted: true,\n        ref: cameraRef,\n        onPlay: () => detectVideo(cameraRef.current, model, canvasRef.current)\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 108,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"video\", {\n        autoPlay: true,\n        muted: true,\n        ref: videoRef,\n        onPlay: () => detectVideo(videoRef.current, model, canvasRef.current)\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 116,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"canvas\", {\n        // width={model.inputShape[1]}\n        // height={model.inputShape[2]}\n        width: canvasRef.width,\n        height: canvasRef.height,\n        ref: canvasRef\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 122,\n        columnNumber: 9\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 101,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 92,\n    columnNumber: 5\n  }, this);\n}\n_s(ContentsBox, \"ARypJciIB5BSNdIIrjek3TlETV8=\");\n_c2 = ContentsBox;\nexport default ContentsBox;\nvar _c, _c2;\n$RefreshReg$(_c, \"ContentContainer\");\n$RefreshReg$(_c2, \"ContentsBox\");","map":null,"metadata":{},"sourceType":"module","externalDependencies":[]}