{"ast":null,"code":"import _regeneratorRuntime from \"/Users/kim-euntae/Documents/Dev/yolov8-nxv/node_modules/@babel/runtime/helpers/esm/regeneratorRuntime.js\";\nimport _asyncToGenerator from \"/Users/kim-euntae/Documents/Dev/yolov8-nxv/node_modules/@babel/runtime/helpers/esm/asyncToGenerator.js\";\nimport _slicedToArray from \"/Users/kim-euntae/Documents/Dev/yolov8-nxv/node_modules/@babel/runtime/helpers/esm/slicedToArray.js\";\nimport React, { useEffect, useRef, useState } from \"react\";\nimport { styled } from \"@mui/material\";\nimport * as tf from \"@tensorflow/tfjs\";\nimport { detect, detectVideo } from \"../shared/detect\";\nimport ButtonHandler from \"./BtnHandler\";\nimport { jsx as _jsx } from \"react/jsx-runtime\";\nimport { jsxs as _jsxs } from \"react/jsx-runtime\";\nvar Content = /*#__PURE__*/styled(\"div\")(function (_ref) {\n  var theme = _ref.theme;\n  return {\n    width: \"100%\",\n    height: \"100%\"\n  };\n});\nfunction ContentsBox(_ref2) {\n  var file = _ref2.file;\n  var _useState = useState({\n      net: null,\n      inputShape: [1, 0, 0, 3]\n    }),\n    _useState2 = _slicedToArray(_useState, 2),\n    model = _useState2[0],\n    setModel = _useState2[1]; // init model & input shape\n\n  var imageRef = useRef(null);\n  var cameraRef = useRef(null);\n  var videoRef = useRef(null);\n  var canvasRef = useRef(null);\n\n  // model configs\n  var modelName = \"yolov8n\";\n  useEffect(function () {\n    tf.ready().then( /*#__PURE__*/_asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee() {\n      var yolov8, dummyInput, warmupResults;\n      return _regeneratorRuntime().wrap(function _callee$(_context) {\n        while (1) switch (_context.prev = _context.next) {\n          case 0:\n            _context.next = 2;\n            return tf.loadGraphModel(\"\".concat(window.location.href, \"/\").concat(modelName, \"_web_model/model.json\"), {\n              onProgress: function onProgress(fractions) {\n                // setLoading({ loading: true, progress: fractions }); // set loading fractions\n              }\n            });\n          case 2:\n            yolov8 = _context.sent;\n            // load model\n            // warming up model\n            dummyInput = tf.ones(yolov8.inputs[0].shape);\n            warmupResults = yolov8.execute(dummyInput); // setLoading({ loading: false, progress: 1 });\n            setModel({\n              net: yolov8,\n              inputShape: yolov8.inputs[0].shape\n            }); // set model & input shape\n\n            tf.dispose([warmupResults, dummyInput]); // cleanup memory\n          case 7:\n          case \"end\":\n            return _context.stop();\n        }\n      }, _callee);\n    })));\n  }, []);\n  return /*#__PURE__*/_jsxs(Content, {\n    children: [/*#__PURE__*/_jsxs(\"div\", {\n      children: [/*#__PURE__*/_jsx(\"image\", {\n        src: file,\n        alt: \"image-result\",\n        onLoad: function onLoad() {\n          return detect(imageRef.current, model, canvasRef.current);\n        }\n      }), /*#__PURE__*/_jsx(\"video\", {\n        autoPlay: true,\n        muted: true,\n        onPlay: function onPlay() {\n          return detectVideo(cameraRef.current, model, canvasRef.current);\n        }\n      }), /*#__PURE__*/_jsx(\"video\", {\n        autoPlay: true,\n        muted: true,\n        onPlay: function onPlay() {\n          return detectVideo(videoRef.current, model, canvasRef.current);\n        }\n      }), /*#__PURE__*/_jsx(\"canvas\", {\n        width: model.inputShape[1],\n        height: model.inputShape[2],\n        ref: canvasRef\n      })]\n    }), /*#__PURE__*/_jsx(ButtonHandler, {\n      imageRef: imageRef,\n      cameraRef: cameraRef,\n      videoRef: videoRef\n    })]\n  });\n}\nexport default ContentsBox;","map":null,"metadata":{},"sourceType":"module","externalDependencies":[]}